{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained and transfer learning with keras\n",
    "\n",
    "Oftentimes, we are not going to reinvent the wheel, but use a **pre-trained network** to recognize entities. For some applications, there are very performant out-of-the-box solutions, and making your own model from scratch would be a waste of your valuable time.\n",
    "\n",
    "Other times, you have an application for which the out-of-the-box solutions are not exactly what you need. For this, you could use **transfer learning** to adapt a network for your use case. We will view both cases here.\n",
    "\n",
    "## 1. Pre-trained model usage\n",
    "\n",
    "In this chapter, we will learn how to import a **keras** model that has been pre-trained to recognize various objects in full-color images.\n",
    "\n",
    "### 1.1 Importing an existing model\n",
    "\n",
    "Head on over to the official [keras applications](https://keras.io/api/applications/) webpage to check out what models are there to pick and choose for our object recognition task.\n",
    "\n",
    "For this exercise, **you** can choose what network to pick. Look online what models are often used, or look at the evaluation metrics on the given webpage to determine which one is fit for the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your chosen model!\n",
    "# from tensorflow.keras.applications... import ...\n",
    "\n",
    "# Make a model object. Make sure you include the top as well!\n",
    "# model = ...\n",
    "\n",
    "# Look at the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Preparing your images\n",
    "\n",
    "Go raid your Google photos or the World Wide Web for some pictures you want to get identified! Be sure to **pick pictures with only one clear object** inside. When you get to OpenCV model usage, you'll learn how to properly identify regions of interest in an image, but let's take one thing at a time here and keep our images simple.\n",
    "\n",
    "Keras also has a neat function to preprocess images **in the same way the training images for a network were preprocessed**. This is pretty handy to improve the model performance with those seedy pictures you found in your personal stash.\n",
    "\n",
    "Things like pixel scaling or color contrasting are applied using these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the keras preprocessing method\n",
    "# from keras.applications... import preprocess_input\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load your image. Make sure it is loaded in with the right dimensions for your model!\n",
    "# img = image.load_img(...\n",
    "\n",
    "# Convert your image pixels to a numpy array of values. \n",
    "# img = image.img_to_array(...\n",
    "\n",
    "# reshape your image dimensions so that the colour channels correspond to what your model expects.\n",
    "# img = img.reshape(...\n",
    "\n",
    "# preprocess your image with preprocess_input\n",
    "# prepared_image = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Predicting the class of your image\n",
    "\n",
    "Let's take this bad boy for a spin! Can your image get properly identified? Finish the code down below and find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.applications... import decode_predictions\n",
    "\n",
    "# Predict the class of your picture.\n",
    "# prediction = model.predict(...\n",
    "\n",
    "# Decode your prediction into a set of human readable labels.\n",
    "# labels = decode_predictions(...\n",
    "\n",
    "# Get the most likely result from your set of labels.\n",
    "# label = ...\n",
    "\n",
    "# Print out your result.\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, how did we do? Your final result should return a general label of the object in the picture, but the performance might not be up to your expectation. Why is this? \n",
    "\n",
    "This could be due to the fact that these are general object recognition models, they are trained on **a lot** of images, but also a lot of different classes of images. What would happen if you took the best part of your pre-trained network, and adapt the output to specialize to just a few of your own chosen classes? Let's check this out in the next part...\n",
    "\n",
    "## 2. Transfer learning\n",
    "\n",
    "Many of the steps of pre-trained model learning still apply to transfer learning, but this time around, we're going to use our own dataset to help the model specialize in a particular subject.\n",
    "\n",
    "Take a look at the image below: \n",
    "![low-to-high](./../assets/low-to-high.png)\n",
    "\n",
    "It shows how a particular object is recognized at the different stages of a CNN. With our pre-trained CNN, it's no different. Instead of re-training a full neural network to extract low-level features such as lines, or other common patterns, we **keep the general feature extraction** of a pre-trained network and **replace the nonlinear association of features** done in the last few dense layers of the network.\n",
    "\n",
    "Some features may be shared by multiple classes in our use case (with animals, this is often the case), while others are only specific to a single class of the network. That's quite okay though, even if the model has been trained to extract features from classes not present in the final set of classes, this is training you don't have to redo anyway. The only difference is a small redundancy and (non-noticeable) slowdown during model prediction because of the larger model size.\n",
    "\n",
    "So in short, the advantages of transfer learning are:\n",
    "- No need to train a whole model from scratch.\n",
    "- Less training data required (less DOF (degrees of freedom) to fill).\n",
    "- Lower level feature extraction from pre-trained networks can be reused.\n",
    "- Output classes can be changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Importing and preprocessing the data\n",
    "\n",
    "Having a general model is all fine and dandy, but I want to **relax** the object identification problem by **reducing** the amount of classes in our model. I want a model that can accurately **identify hot dogs** from not hot dogs!\n",
    "\n",
    "Go and download the data from [this Kaggle dataset](https://www.kaggle.com/dansbecker/hot-dog-not-hot-dog), and go through the motions of preparing the data for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the keras preprocessing method\n",
    "# from keras.applications... import preprocess_input\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "# import numpy as np\n",
    "\n",
    "# Load your images. Make sure they are loaded in with the right dimensions for your model!\n",
    "# hot_dog_images = ...\n",
    "# non_hot_dog_images = ...\n",
    "\n",
    "# Convert your image pixels to a numpy array of values (take a look at the 'image_to_array' method from image).\n",
    "# hot_dog_images = ...\n",
    "# non_hot_dog_images = ...\n",
    "\n",
    "# Reshape your image dimensions so that the color channels correspond to what your model expects.\n",
    "# hot_dog_images = ...\n",
    "# non_hot_dog_images = ...\n",
    "\n",
    "# Preprocess your image with preprocess_input.\n",
    "# hot_dog_images = ...\n",
    "# non_hot_dog_images = ...\n",
    "\n",
    "# Make a numpy array for each of the class labels (one hot encoded depending on your loss function).\n",
    "# hot_dog_labels = ...\n",
    "# non_hot_dog_labels = ...\n",
    "\n",
    "# Concatenate your images and your labels into X and y\n",
    "# X = ...\n",
    "# y = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always when training a model, we need to split our data in a train and a test set. For deep learning, a validation set is oftentimes used as well. Kind of foggy on the [different purposes](https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7) of these sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, \n",
    "    y,\n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, \n",
    "    y_train_val,\n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Augmenting the data\n",
    "\n",
    "We don't have that many hot dogs to look at, let's squeeze as much information out of the training data by augmenting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Determine the number of generated samples you want per original sample.\n",
    "# datagen_batch_size = ...\n",
    "\n",
    "# Make a datagenerator object using ImageDataGenerator.\n",
    "# train_datagen = ...\n",
    "\n",
    "# Feed the generator your train data (use the flow function).\n",
    "# train_generator = ...\n",
    "\n",
    "# Make a datagenerator object using ImageDataGenerator.\n",
    "# validation_datagen = ...\n",
    "\n",
    "# Feed the generator your validation data (use the flow function).\n",
    "# validation_generator = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Importing part of an existing model\n",
    "\n",
    "Let's import one of the application of the Keras library, but make sure you don't import the final layers (the dense layers used to associate features). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your chosen model!\n",
    "# from tensorflow.keras.applications... import ...\n",
    "\n",
    "# Make a model object. \n",
    "# Make sure you exclude the top part. Set the input shape of the model to 224x224 pixels, with 3 color channels.\n",
    "# model = ...\n",
    "\n",
    "# Freeze the imported layers so they cannot be retrained.\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Adding flattening and dense layers\n",
    "\n",
    "Right now, our model is missing a top to actually classify our features. Let's add them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "\n",
    "# Add new classifier layers. Make sure our your model will only classify 2 classes!\n",
    "new_model = Sequential()\n",
    "# new_model.add(...\n",
    "\n",
    "# Summarize\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Training and evaluating the model\n",
    "\n",
    "All that's left to do is to train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model. Use the Adam optimizer and crossentropical loss. \n",
    "# Make sure you use your data augmentation generators instead of your original data.\n",
    "# new_model.compile(...\n",
    "# new_model.fit(..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how you did with this handy helper function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history : tensorflow.python.keras.callbacks.History):\n",
    "    \"\"\" This helper function takes the tensorflow.python.keras.callbacks.History\n",
    "    that is output from your `fit` method to plot the loss and accuracy of\n",
    "    the training and validation set.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(1,2, figsize=(12,6))\n",
    "    axs[0].plot(history.history['accuracy'], label='training set')\n",
    "    axs[0].plot(history.history['val_accuracy'], label = 'validation set')\n",
    "    axs[0].set(xlabel = 'Epoch', ylabel='Accuracy', ylim=[0, 1])\n",
    "\n",
    "    axs[1].plot(history.history['loss'], label='training set')\n",
    "    axs[1].plot(history.history['val_loss'], label = 'validation set')\n",
    "    axs[1].set(xlabel = 'Epoch', ylabel='Loss', ylim=[0, 10])\n",
    "    \n",
    "    axs[0].legend(loc='lower right')\n",
    "    axs[1].legend(loc='lower right')\n",
    "    \n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, no test is complete without you digging up shady hot dog pics to test out the final product! Did it identify your hot dog? Test it out below! Don't forget to use your test images as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the class of your picture.\n",
    "# prediction = new_model.predict(..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
