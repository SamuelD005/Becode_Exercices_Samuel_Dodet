{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object recognition drills\n",
    "\n",
    "You've seen an example of a simple neural network in the [previous](./5.object_recognition_from_scratch_with_keras.ipynb) [chapters](./6.object_recognition_from_scratch_with_pytorch.ipynb), but can you make your own as well? Let's flex our neural skills and **extend** the model from the previous chapter.\n",
    "\n",
    "## Multiple classes\n",
    "\n",
    "The previous model was alright in separating cats from dogs, but what if we want to add on more classes? Extend the previous model by **adding more classes** from the Google [\"quick,draw!\" dataset](https://console.cloud.google.com/storage/browser/quickdraw_dataset/full/numpy_bitmap). \n",
    "\n",
    "Choose 6 classes of your own, train and test your model as shown in the previous notebook. You might need to change the model structure a bit to deal with the new classes. Hint: choose yourself some visually distinct classes to make your life a bit easier.\n",
    "\n",
    "You can choose whether you want to use keras or pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extend the model shown in the previous chapter to recognise 6 different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full-color dataset\n",
    "\n",
    "Drawings are nice, but how good are CNN's for nice color pictures? Download [this](https://www.kaggle.com/moltean/fruits) dataset to get pictures of fruits and vegetables. Design (or use transfer learning) and evaluate a CNN to classify these (remember; these are RGB color pictures). \n",
    "\n",
    "Hint: take some inspiration from already successful and [popular CNN architectures](https://www.topbots.com/important-cnn-architectures/), from [keras built-in NN models](https://keras.io/api/applications/) or [pytorch built-in ones](https://pytorch.org/vision/0.8/models.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design and evaluate a CNN for classifying fruits and vegetables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing feature extraction\n",
    "\n",
    "Alright, time for some nice visualizations! Neural networks are notoriously **hard to interpret**, and all their hidden variables make for a very **unobservable** transformation. How can we, as humans, still visualize our neural network, though?\n",
    "\n",
    "We can visualize the feature maps, which is what each convolutional layer 'sees' after the filters are applied. Follow the steps described in [this article](https://machinelearningmastery.com/how-to-visualize-filters-and-feature-maps-in-convolutional-neural-networks/) to try this out on your fruit CNN! (or one of the CNN's in the previous chapters in case you have not finished the previous drill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the feature maps of your fruit CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
