{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the perceptron theory\n",
    "Although we're going to use the `tensorflow` library, we're going to mainly use the high level library [`keras`](https://keras.io/), that was previously standalone but got integrated into the newer version of tensorflow when it's author, [Francois Chollet](https://twitter.com/fchollet?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor), went to work for Google.\n",
    "\n",
    "We'll be coding the same neural network as we did in for `pytorch`. Make sure to review it before diving into this chapter, as I will not re-explain everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like the previous chapter, load the same dataset using the same method. However, no need to convert them to tensors, as we are not using `pytorch` anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO COMPLETE:  Load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting some constants\n",
    "nb_hidden_neurons = 10\n",
    "nb_classes = len(pd.unique(df['species']))\n",
    "nb_features= X_train.shape[1]\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `keras`, there are [three ways](https://www.pyimagesearch.com/2019/10/28/3-ways-to-create-a-keras-model-with-tensorflow-2-0-sequential-functional-and-model-subclassing/) to build a neural network. We are going to focus on the `Sequential` mode, so that you can see different ways of building one. In `pytorch`, we mostly did something similar to the model subclassing and functional approach of keras.\n",
    "\n",
    "Here below, we want you to construct the model architecture; the same one that was used in the previous chapter. You see a recap below.\n",
    "\n",
    "*Hint: a linear layer in keras is `keras.layers.Dense`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO COMPLETE: Construct the architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO COMPLETE: Build the model with `model.build()`. You might need to specify the `input_shape`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model.summary()` should return the following if you've done everything right\n",
    "\n",
    "```\n",
    "Model: \"sequential_2\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_6 (Dense)              (None, 10)                50        \n",
    "_________________________________________________________________\n",
    "dense_7 (Dense)              (None, 10)                110       \n",
    "_________________________________________________________________\n",
    "dense_8 (Dense)              (None, 3)                 33        \n",
    "=================================================================\n",
    "Total params: 193\n",
    "Trainable params: 193\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO COMPLETE:\n",
    "# - set learning rate\n",
    "# - set loss\n",
    "# - set optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making sure the type is correct\n",
    "X_train = X_train.astype(\"float32\")\n",
    "y_train = y_train.astype(\"float32\")\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO COMPLETE:\n",
    "# - compile the model using `model.compile()` and the variables set before\n",
    "# - create a variable `history`\n",
    "# - fit the model and assign the result to `history`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1,ncols=2,figsize=(10,4))\n",
    "axs[0].plot(range(len(loss)), loss)\n",
    "axs[0].set(xlabel=\"Epochs\", ylabel=\"Loss\", title=\"Training loss\")\n",
    "axs[1].plot(range(len(accuracy)), accuracy)\n",
    "axs[1].set(xlabel=\"Epochs\", ylabel=\"Accuracy\", title=\"Training accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss shall decrease and the accuracy shall increase. You should get something similar to this.\n",
    "![Loss and accuracy ](./assets/tf_loss_and_accuracy.png)\n",
    "\n",
    "Moreover, testing on the testing set shall result in a (near) perfect score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO COMPLETE: Evaluate the model on the test set.\n",
    "print(f\"\\nAccuracy on test set is {results[1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Voil√†*, you've seen both approaches to create a neural network. Of course, there are still MANY things to learn about `pytorch` and `keras`, we've barely even scratched the surface. But now that you know the basics, you will be able to test them out on a new project!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
